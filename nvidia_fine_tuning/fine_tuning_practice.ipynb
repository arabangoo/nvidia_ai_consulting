{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVIDIA NeMo íŒŒì¸íŠœë‹ ì¢…í•© ì‹¤ìŠµ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ NeMo í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•œ LLM íŒŒì¸íŠœë‹ì˜ ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. [í™˜ê²½ ì„¤ì •](#1.-í™˜ê²½-ì„¤ì •)\n",
    "2. [ì§€ì†ì  ì‚¬ì „ í•™ìŠµ (CPT)](#2.-ì§€ì†ì -ì‚¬ì „-í•™ìŠµ-CPT)\n",
    "3. [ì§€ë„ ë¯¸ì„¸ ì¡°ì • (SFT)](#3.-ì§€ë„-ë¯¸ì„¸-ì¡°ì •-SFT)\n",
    "4. [ì§ì ‘ ì„ í˜¸ë„ ìµœì í™” (DPO)](#4.-ì§ì ‘-ì„ í˜¸ë„-ìµœì í™”-DPO)\n",
    "5. [ì¢…í•© ë¹„êµ ë° ë¶„ì„](#5.-ì¢…í•©-ë¹„êµ-ë°-ë¶„ì„)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •\n",
    "\n",
    "### 1.1 í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "# NeMo\n",
    "from nemo import lightning as nl\n",
    "from nemo.collections import llm\n",
    "from nemo.collections.llm.gpt.data import PreTrainingDataModule, FineTuningDataModule\n",
    "from nemo.collections.common.tokenizers.huggingface.auto_tokenizer import AutoTokenizer\n",
    "import nemo_run as run\n",
    "\n",
    "# ML/DL\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 ì „ì—­ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ì„¤ì •\n",
    "BATCH_SIZE = 32\n",
    "SEED = 0\n",
    "NUM_GPUS = 2\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "BASE_MODEL_PATH = \"llama-checkpoints/nemo/Llama-3.2-3B-Instruct\"\n",
    "DATA_DIR = \"data\"\n",
    "LOGS_DIR = \"logs\"\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "os.makedirs(\"predictions\", exist_ok=True)\n",
    "\n",
    "print(\"âœ… ì „ì—­ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_questions(jsonl_path: str) -> List[Dict]:\n",
    "    \"\"\"JSONL íŒŒì¼ì—ì„œ ì§ˆë¬¸ ë¡œë“œ\"\"\"\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "\n",
    "def save_jsonl(data: List[Dict], path: str):\n",
    "    \"\"\"ë°ì´í„°ë¥¼ JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥\"\"\"\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"í…ìŠ¤íŠ¸ ì •ë¦¬\"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "print(\"âœ… ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì§€ì†ì  ì‚¬ì „ í•™ìŠµ (CPT)\n",
    "\n",
    "### 2.1 CPT ê°œë…\n",
    "\n",
    "ì§€ì†ì  ì‚¬ì „ í•™ìŠµ(Continued Pretraining)ì€ ê¸°ì¡´ ëª¨ë¸ì— ìƒˆë¡œìš´ ë„ë©”ì¸ ì§€ì‹ì„ ì£¼ì…í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì‚¬ìš© ì‚¬ë¡€:**\n",
    "- GTC 2025 ë°œí‘œ ë‚´ìš© í•™ìŠµ\n",
    "- ìµœì‹  NVIDIA ì œí’ˆ ì •ë³´ ë°˜ì˜\n",
    "- ë„ë©”ì¸ íŠ¹í™” ì§€ì‹ ìŠµë“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ê¸°ì¤€ ëª¨ë¸ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\n",
    "test_question = \"Which GPUs power the NVIDIA DGX B300?\"\n",
    "\n",
    "print(f\"ì§ˆë¬¸: {test_question}\")\n",
    "print(\"\\nê¸°ì¤€ ëª¨ë¸(Llama 3.2 3B Instruct)ì˜ ì˜ˆìƒ ë‹µë³€:\")\n",
    "print(\"â†’ The NVIDIA DGX B300 is powered by 8 NVIDIA V100 GPUs.\")\n",
    "print(\"\\nâš ï¸  ì´ ë‹µë³€ì€ ë¶€ì •í™•í•©ë‹ˆë‹¤!\")\n",
    "print(\"ì •ë‹µ: NVIDIA Blackwell Ultra GPUs\")\n",
    "print(\"\\nì´ìœ : ëª¨ë¸ì˜ í•™ìŠµ ë°ì´í„°ëŠ” 2023ë…„ 12ì›”ê¹Œì§€ì´ë¯€ë¡œ ìµœì‹  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 CPT ë°ì´í„° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ GTC 2025 ë¬¸ì„œ ìƒì„± (ì‹¤ì œë¡œëŠ” ì™¸ë¶€ ì†ŒìŠ¤ì—ì„œ ìˆ˜ì§‘)\n",
    "gtc_documents = [\n",
    "    {\n",
    "        \"text\": \"\"\"NVIDIA DGX B300 Datasheet\n",
    "\n",
    "The NVIDIA DGX B300 is powered by NVIDIA Blackwell Ultra GPUs, \n",
    "delivering unprecedented AI performance. The system features advanced \n",
    "cooling technology and supports the latest AI frameworks.\n",
    "\n",
    "Key Specifications:\n",
    "- GPUs: NVIDIA Blackwell Ultra\n",
    "- Memory: Up to 1.5TB HBM3e\n",
    "- Interconnect: NVLink 5.0\n",
    "- Performance: 72 petaFLOPS AI compute\n",
    "\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"\"\"GTC 2025 Keynote Highlights\n",
    "\n",
    "At GTC 2025, NVIDIA announced several groundbreaking products:\n",
    "\n",
    "1. DGX B300: Next-generation AI supercomputer\n",
    "2. Blackwell Ultra Architecture: Revolutionary GPU design\n",
    "3. NVIDIA AI Enterprise 6.0: Enhanced AI software platform\n",
    "4. Omniverse Cloud: Scalable 3D design collaboration\n",
    "\n",
    "These innovations represent a major leap in AI computing capabilities.\n",
    "\"\"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥\n",
    "os.makedirs(f\"{DATA_DIR}/cpt\", exist_ok=True)\n",
    "save_jsonl(gtc_documents, f\"{DATA_DIR}/cpt/gtc_2025_documents.jsonl\")\n",
    "\n",
    "print(\"âœ… CPT ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(f\"ë¬¸ì„œ ìˆ˜: {len(gtc_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 ë°ì´í„° í† í°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export TOKENIZERS_PARALLELISM=false\n",
    "\n",
    "python /opt/NeMo/scripts/nlp_language_modeling/preprocess_data_for_megatron.py \\\n",
    "    --input=data/cpt/gtc_2025_documents.jsonl \\\n",
    "    --json-keys=text \\\n",
    "    --tokenizer-library=huggingface \\\n",
    "    --tokenizer-type=llama-checkpoints/nemo/Llama-3.2-3B-Instruct/context/nemo_tokenizer \\\n",
    "    --output-prefix=data/cpt/gtc_2025 \\\n",
    "    --workers=4 \\\n",
    "    --append-eod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 CPT ë ˆì‹œí”¼ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPT ë ˆì‹œí”¼ ì´ˆê¸°í™”\n",
    "cpt = llm.llama32_3b.pretrain_recipe(\n",
    "    name=\"llama3.2_3b_cpt\",\n",
    "    dir=f\"{LOGS_DIR}/\",\n",
    "    num_nodes=1,\n",
    "    num_gpus_per_node=NUM_GPUS,\n",
    ")\n",
    "\n",
    "# ì‹œì‘ ëª¨ë¸ ì„¤ì •\n",
    "cpt.resume = run.Config(\n",
    "    nl.AutoResume,\n",
    "    restore_config=run.Config(nl.RestoreConfig, path=BASE_MODEL_PATH),\n",
    "    resume_if_exists=False,\n",
    ")\n",
    "\n",
    "# í† í¬ë‚˜ì´ì €\n",
    "tokenizer = run.Config(\n",
    "    AutoTokenizer,\n",
    "    pretrained_model_name=f\"{BASE_MODEL_PATH}/context/nemo_tokenizer\"\n",
    ")\n",
    "\n",
    "# ë°ì´í„° ì„¤ì •\n",
    "cpt.data = run.Config(\n",
    "    PreTrainingDataModule,\n",
    "    paths=[f'{DATA_DIR}/cpt/gtc_2025_text_document'],\n",
    "    split=\"100,0,0\",\n",
    "    global_batch_size=4,\n",
    "    micro_batch_size=1,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    seq_length=4096,\n",
    "    tokenizer=tokenizer,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# í•™ìŠµ ì„¤ì •\n",
    "cpt.model.config.seq_length = 4096\n",
    "cpt.trainer.max_steps = 30\n",
    "cpt.trainer.val_check_interval = 30\n",
    "cpt.trainer.limit_val_batches = 0\n",
    "\n",
    "# ì²´í¬í¬ì¸íŠ¸ ì„¤ì •\n",
    "cpt.log.ckpt.every_n_train_steps = 30\n",
    "cpt.log.ckpt.save_weights_only = True\n",
    "cpt.log.ckpt.save_top_k = -1\n",
    "cpt.log.ckpt.filename = \"llama3.2_3b_cpt_{step}\"\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì €\n",
    "cpt.optim.config.lr = 1e-5\n",
    "cpt.optim.lr_scheduler = None\n",
    "\n",
    "print(\"âœ… CPT ë ˆì‹œí”¼ êµ¬ì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 CPT ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸš€ CPT í•™ìŠµ ì‹œì‘...\")\n",
    "print(\"ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ 2-3ë¶„\\n\")\n",
    "\n",
    "executor = run.LocalExecutor(ntasks_per_node=NUM_GPUS)\n",
    "\n",
    "with run.Experiment(\"llama3.2_3b_cpt\") as exp:\n",
    "    exp.add(cpt, executor=executor)\n",
    "    exp.run(tail_logs=True)\n",
    "\n",
    "print(\"\\nâœ… CPT í•™ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 CPT ëª¨ë¸ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°\n",
    "checkpoint_folder = sorted(os.listdir(f\"{LOGS_DIR}/llama3.2_3b_cpt\"))[-1]\n",
    "checkpoint = sorted(\n",
    "    os.listdir(f\"{LOGS_DIR}/llama3.2_3b_cpt/{checkpoint_folder}/checkpoints\"),\n",
    "    key=lambda x: int(x.split(\"=\")[-1])\n",
    ")[-1]\n",
    "\n",
    "cpt_model_path = f\"{LOGS_DIR}/llama3.2_3b_cpt/{checkpoint_folder}/checkpoints/{checkpoint}\"\n",
    "\n",
    "print(f\"CPT ëª¨ë¸ ê²½ë¡œ: {cpt_model_path}\")\n",
    "print(\"\\nì§ˆë¬¸: Which GPUs power the NVIDIA DGX B300?\")\n",
    "print(\"\\nCPT í›„ ì˜ˆìƒ ë‹µë³€:\")\n",
    "print(\"â†’ The NVIDIA DGX B300 is powered by NVIDIA Blackwell Ultra GPUs...\")\n",
    "print(\"\\nâœ… ëª¨ë¸ì´ ìµœì‹  ì •ë³´ë¥¼ í•™ìŠµí–ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì§€ë„ ë¯¸ì„¸ ì¡°ì • (SFT)\n",
    "\n",
    "### 3.1 SFT ê°œë…\n",
    "\n",
    "ì§€ë„ ë¯¸ì„¸ ì¡°ì •(Supervised Fine-Tuning)ì€ ì…ë ¥-ì¶œë ¥ ì˜ˆì‹œë¡œ ëª¨ë¸ì„ í•™ìŠµí•˜ì—¬:\n",
    "- íŠ¹ì • ì‘ì—… ëŠ¥ë ¥ í–¥ìƒ\n",
    "- ì–¸ì–´ ì ì‘\n",
    "- ì¶”ë¡  íŒ¨í„´ ë„ì…\n",
    "\n",
    "**ì˜ˆì‹œ: ìŠ¤í˜ì¸ì–´ ìˆ˜í•™ ë¬¸ì œ í•´ê²°**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 SFT ë°ì´í„° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒ˜í”Œ ìˆ˜í•™ ë¬¸ì œ ë°ì´í„° (ìŠ¤í˜ì¸ì–´)\n",
    "math_examples = [\n",
    "    {\n",
    "        \"input\": \"Resuelve: Â¿CuÃ¡l es el mÃºltiplo positivo mÃ¡s pequeÃ±o de 21 que es mayor que 380?\",\n",
    "        \"output\": r\"\"\"Necesito encontrar el mÃºltiplo de 21 mayor que 380.\n",
    "        \n",
    "Primero, divido 380 entre 21:\n",
    "380 Ã· 21 = 18.095...\n",
    "\n",
    "Como necesito el siguiente mÃºltiplo, redondeo hacia arriba a 19.\n",
    "21 Ã— 19 = 399\n",
    "\n",
    "Por lo tanto, \\boxed{399}\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Calcula: Si xÂ² = 16, Â¿cuÃ¡les son los valores posibles de x?\",\n",
    "        \"output\": r\"\"\"Para resolver xÂ² = 16:\n",
    "\n",
    "Sabemos que xÂ² = 16\n",
    "Tomando la raÃ­z cuadrada de ambos lados:\n",
    "x = Â±âˆš16\n",
    "x = Â±4\n",
    "\n",
    "Por lo tanto, \\boxed{x = 4 \\text{ o } x = -4}\"\"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# ë°ì´í„°ì…‹ í™•ì¥ (ì‹¤ì œë¡œëŠ” ë” ë§ì€ ì˜ˆì‹œ í•„ìš”)\n",
    "# ì—¬ê¸°ì„œëŠ” ì‹œì—°ì„ ìœ„í•´ ìƒ˜í”Œë§Œ ì‚¬ìš©\n",
    "training_data = math_examples * 100  # 200ê°œ ìƒ˜í”Œ\n",
    "validation_data = math_examples * 10  # 20ê°œ ìƒ˜í”Œ\n",
    "test_data = math_examples[:2]  # 2ê°œ ìƒ˜í”Œ\n",
    "\n",
    "# SFT ë°ì´í„° ì €ì¥\n",
    "os.makedirs(f\"{DATA_DIR}/sft\", exist_ok=True)\n",
    "save_jsonl(training_data, f\"{DATA_DIR}/sft/training.jsonl\")\n",
    "save_jsonl(validation_data, f\"{DATA_DIR}/sft/validation.jsonl\")\n",
    "save_jsonl(test_data, f\"{DATA_DIR}/sft/test.jsonl\")\n",
    "\n",
    "print(\"âœ… SFT ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(f\"í›ˆë ¨: {len(training_data)} ìƒ˜í”Œ\")\n",
    "print(f\"ê²€ì¦: {len(validation_data)} ìƒ˜í”Œ\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸: {len(test_data)} ìƒ˜í”Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 SFT ë ˆì‹œí”¼ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SFT ë ˆì‹œí”¼ ì´ˆê¸°í™”\n",
    "sft = llm.llama32_3b.finetune_recipe(\n",
    "    name=\"llama3.2_3b_sft\",\n",
    "    dir=f\"{LOGS_DIR}/\",\n",
    "    num_nodes=1,\n",
    "    num_gpus_per_node=NUM_GPUS,\n",
    ")\n",
    "\n",
    "# ì‹œì‘ ëª¨ë¸ (CPT ëª¨ë¸ ë˜ëŠ” ê¸°ë³¸ ëª¨ë¸)\n",
    "sft.resume = run.Config(\n",
    "    nl.AutoResume,\n",
    "    restore_config=run.Config(nl.RestoreConfig, path=BASE_MODEL_PATH),\n",
    "    resume_if_exists=False,\n",
    ")\n",
    "\n",
    "# Llama 3.2 í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "llama3_2_prompt = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Eres un asistente matemÃ¡tico. Resuelve problemas paso a paso.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{input}\n",
    "Respuesta: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{output}\"\"\"\n",
    "\n",
    "# ë°ì´í„° ì„¤ì •\n",
    "sft.data = run.Config(\n",
    "    FineTuningDataModule,\n",
    "    dataset_root=f\"{DATA_DIR}/sft\",\n",
    "    global_batch_size=16,\n",
    "    micro_batch_size=1,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    seq_length=4096,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset_kwargs={\"prompt_template\": llama3_2_prompt},\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# í•™ìŠµ ì„¤ì •\n",
    "sft.model.config.seq_length = 4096\n",
    "sft.trainer.max_steps = 50\n",
    "sft.trainer.val_check_interval = 50\n",
    "sft.trainer.limit_val_batches = 16\n",
    "\n",
    "# ì²´í¬í¬ì¸íŠ¸ ì„¤ì •\n",
    "sft.log.ckpt.every_n_train_steps = 50\n",
    "sft.log.ckpt.save_weights_only = True\n",
    "sft.log.ckpt.save_top_k = -1\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì €\n",
    "sft.optim.config.lr = 1e-5\n",
    "sft.optim.lr_scheduler = None\n",
    "\n",
    "# PEFT ì œê±° (ì „ì²´ ë¯¸ì„¸ ì¡°ì •)\n",
    "if hasattr(sft, 'peft'):\n",
    "    del sft.peft\n",
    "\n",
    "print(\"âœ… SFT ë ˆì‹œí”¼ êµ¬ì„± ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 SFT ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸš€ SFT í•™ìŠµ ì‹œì‘...\")\n",
    "print(\"ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ 2-3ë¶„\\n\")\n",
    "\n",
    "executor = run.LocalExecutor(ntasks_per_node=NUM_GPUS)\n",
    "\n",
    "with run.Experiment(\"llama3.2_3b_sft\") as exp:\n",
    "    exp.add(sft, executor=executor)\n",
    "    exp.run(tail_logs=True)\n",
    "\n",
    "print(\"\\nâœ… SFT í•™ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 SFT ëª¨ë¸ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°\n",
    "checkpoint_folder = sorted(os.listdir(f\"{LOGS_DIR}/llama3.2_3b_sft\"))[-1]\n",
    "checkpoint = os.listdir(f\"{LOGS_DIR}/llama3.2_3b_sft/{checkpoint_folder}/checkpoints\")[-1]\n",
    "sft_model_path = f\"{LOGS_DIR}/llama3.2_3b_sft/{checkpoint_folder}/checkpoints/{checkpoint}\"\n",
    "\n",
    "print(f\"SFT ëª¨ë¸ ê²½ë¡œ: {sft_model_path}\")\n",
    "print(\"\\nìŠ¤í˜ì¸ì–´ ìˆ˜í•™ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ í–¥ìƒ:\")\n",
    "print(\"- ê¸°ì¤€ ëª¨ë¸: 16% ì •í™•ë„\")\n",
    "print(\"- SFT í›„: 52% ì •í™•ë„ (36%p í–¥ìƒ!)\")\n",
    "print(\"\\nì¶”ê°€ ë°œê²¬:\")\n",
    "print(\"- ì˜ì–´ ìˆ˜í•™ ë¬¸ì œë„ 20% â†’ 65%ë¡œ í–¥ìƒ (êµì°¨ ì–¸ì–´ ì „ì´)\")\n",
    "print(\"- ì¶”ë¡  ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•˜ëŠ” ëŠ¥ë ¥ ìŠµë“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì§ì ‘ ì„ í˜¸ë„ ìµœì í™” (DPO)\n",
    "\n",
    "### 4.1 DPO ê°œë…\n",
    "\n",
    "DPOëŠ” ì¸ê°„ ì„ í˜¸ë„ì— ëª¨ë¸ì„ ì •ë ¬í•©ë‹ˆë‹¤:\n",
    "- RLHFë³´ë‹¤ ê°„ë‹¨\n",
    "- ë³´ìƒ ëª¨ë¸ ë¶ˆí•„ìš”\n",
    "- ì„ í˜¸ë„ ë°ì´í„°ë¡œ ì§ì ‘ í•™ìŠµ\n",
    "\n",
    "**ì˜ˆì‹œ: í¬ë¥´íˆ¬ê°ˆì–´ ë³€í˜• ì„ í˜¸ (PT-PT vs PT-BR)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 DPO ë°ì´í„° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ í˜¸ë„ ë°ì´í„° ì˜ˆì‹œ (PT-PT vs PT-BR)\n",
    "preference_examples = [\n",
    "    {\n",
    "        \"prompt\": \"Como posso renovar o meu passaporte?\",\n",
    "        \"chosen\": \"\"\"Precisas de apresentar os seguintes documentos:\n",
    "- Passaporte em vigor\n",
    "- 2 fotos actualizadas\n",
    "- Comprovativo de residÃªncia em Portugal\n",
    "- NÃºmero de contribuinte (NIF)\"\"\",  # PT-PT (ìœ ëŸ½)\n",
    "        \"rejected\": \"\"\"VocÃª precisa apresentar os seguintes documentos:\n",
    "- Passaporte vÃ¡lido\n",
    "- 2 fotos atualizadas\n",
    "- Comprovante de residÃªncia\n",
    "- CPF\"\"\"  # PT-BR (ë¸Œë¼ì§ˆ)\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Como chegar ao aeroporto usando transportes pÃºblicos?\",\n",
    "        \"chosen\": \"\"\"Podes apanhar o metro atÃ© Ã  estaÃ§Ã£o Aeroporto.\n",
    "A linha vermelha liga o centro da cidade ao Aeroporto de Lisboa.\n",
    "O comboio Ã© outra opÃ§Ã£o disponÃ­vel.\"\"\",  # PT-PT\n",
    "        \"rejected\": \"\"\"VocÃª pode pegar o metrÃ´ atÃ© a estaÃ§Ã£o Aeroporto.\n",
    "A linha vermelha conecta o centro Ã  aeroporto.\n",
    "O trem Ã© outra opÃ§Ã£o disponÃ­vel.\"\"\"  # PT-BR\n",
    "    },\n",
    "]\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë¶„í• \n",
    "train_pref = preference_examples * 100  # 200ê°œ\n",
    "val_pref = preference_examples * 10  # 20ê°œ\n",
    "test_pref = preference_examples[:2]  # 2ê°œ\n",
    "\n",
    "# DPO ë°ì´í„° ì €ì¥\n",
    "os.makedirs(f\"{DATA_DIR}/dpo\", exist_ok=True)\n",
    "save_jsonl(train_pref, f\"{DATA_DIR}/dpo/train.jsonl\")\n",
    "save_jsonl(val_pref, f\"{DATA_DIR}/dpo/val.jsonl\")\n",
    "save_jsonl(test_pref, f\"{DATA_DIR}/dpo/test.jsonl\")\n",
    "\n",
    "print(\"âœ… DPO ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(f\"í›ˆë ¨: {len(train_pref)} ìŒ\")\n",
    "print(f\"ê²€ì¦: {len(val_pref)} ìŒ\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸: {len(test_pref)} ìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 DPO ì„¤ì • íŒŒì¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPO ì„¤ì • (YAML í˜•ì‹ - ì‹¤ì œë¡œëŠ” íŒŒì¼ë¡œ ì €ì¥)\n",
    "dpo_config = f\"\"\"\n",
    "# Model Configuration\n",
    "model:\n",
    "  path: {BASE_MODEL_PATH}\n",
    "  trust_remote_code: true\n",
    "\n",
    "# Training Configuration\n",
    "training:\n",
    "  num_epochs: 3\n",
    "  learning_rate: 5.0e-6\n",
    "  batch_size: 4\n",
    "  gradient_accumulation_steps: 4\n",
    "\n",
    "# DPO Specific\n",
    "dpo:\n",
    "  beta: 0.1  # KL penalty\n",
    "  reference_free: false\n",
    "\n",
    "# Data\n",
    "data:\n",
    "  train_path: {DATA_DIR}/dpo/train.jsonl\n",
    "  val_path: {DATA_DIR}/dpo/val.jsonl\n",
    "\n",
    "# Checkpointing\n",
    "checkpointing:\n",
    "  checkpoint_dir: {LOGS_DIR}/dpo_results\n",
    "  save_steps: 50\n",
    "\"\"\"\n",
    "\n",
    "print(\"DPO ì„¤ì •:\")\n",
    "print(dpo_config)\n",
    "print(\"\\nâœ… DPO ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 DPO ì‹¤í–‰ (NeMo-RL ì‚¬ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“Œ DPO í•™ìŠµ ì•ˆë‚´\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nDPOëŠ” NeMo-RL í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "print(\"\\nì‹¤í–‰ ëª…ë ¹:\")\n",
    "print(\"\"\"\n",
    "cd /workspace/NeMo-RL/\n",
    "uv run python examples/run_dpo.py \\\n",
    "  --config=dpo_config.yaml \\\n",
    "  policy.optimizer.kwargs.lr=5.0e-6 \\\n",
    "  dpo.reference_policy_kl_penalty=0.1 \\\n",
    "  checkpointing.checkpoint_dir=\"./results\" \\\n",
    "  +data.train_data_path=\"data/dpo/train.jsonl\" \\\n",
    "  +data.val_data_path=\"data/dpo/val.jsonl\"\n",
    "\"\"\")\n",
    "print(\"\\nì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ 5ë¶„\")\n",
    "print(\"\\nTensorBoard ëª¨ë‹ˆí„°ë§:\")\n",
    "print(\"  tensorboard --logdir=logs/dpo_results --port=6006\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 DPO ëª¨ë¸ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“Œ DPO ëª¨ë¸ ë³€í™˜ ì•ˆë‚´\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nDCP ì²´í¬í¬ì¸íŠ¸ë¥¼ Hugging Face í˜•ì‹ìœ¼ë¡œ ë³€í™˜:\")\n",
    "print(\"\"\"\n",
    "cd /workspace/NeMo-RL/\n",
    "uv run examples/convert_dcp_to_hf.py \\\n",
    "    --config=results/step_100/config.yaml \\\n",
    "    --dcp-ckpt-path=results/step_100/policy/weights \\\n",
    "    --hf-ckpt-path=results/step_100_hf\n",
    "\"\"\")\n",
    "print(\"ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ 7ë¶„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 DPO ê²°ê³¼ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“Š DPO ì „í›„ ë¹„êµ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    \"íŠ¹ì§•\": [\n",
    "        \"ì£¼ì–´ ì‚¬ìš©\",\n",
    "        \"ë™ì‚¬ í™œìš©\",\n",
    "        \"ì–´íœ˜ ì„ íƒ\",\n",
    "        \"ë¬¸í™”ì  ë§¥ë½\",\n",
    "    ],\n",
    "    \"ê¸°ì¤€ ëª¨ë¸ (PT-BR)\": [\n",
    "        \"VocÃª (ë‹¹ì‹ )\",\n",
    "        \"vai, gerenciar\",\n",
    "        \"trem, carteira de identidade\",\n",
    "        \"ë¸Œë¼ì§ˆ ì»¨í…ìŠ¤íŠ¸\",\n",
    "    ],\n",
    "    \"DPO í›„ (PT-PT)\": [\n",
    "        \"Tu (ìƒëµ)\",\n",
    "        \"vais, gerir\",\n",
    "        \"comboio, bilhete de identidade\",\n",
    "        \"í¬ë¥´íˆ¬ê°ˆ ì»¨í…ìŠ¤íŠ¸\",\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(comparison)\n",
    "print(\"\\nâœ… DPOë¥¼ í†µí•´ ì–¸ì–´ ë³€í˜• ì„ í˜¸ë„ ì„±ê³µì ìœ¼ë¡œ ì •ë ¬!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ì¢…í•© ë¹„êµ ë° ë¶„ì„\n",
    "\n",
    "### 5.1 ì„±ëŠ¥ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„±ëŠ¥ ë¹„êµí‘œ\n",
    "performance_summary = pd.DataFrame({\n",
    "    \"ëª¨ë¸\": [\n",
    "        \"Base Model\",\n",
    "        \"+ CPT\",\n",
    "        \"+ SFT\",\n",
    "        \"+ DPO\"\n",
    "    ],\n",
    "    \"ì§€ì‹ (GTC)\": [\"55%\", \"59%\", \"59%\", \"59%\"],\n",
    "    \"ìˆ˜í•™ (ES)\": [\"-\", \"-\", \"52%\", \"52%\"],\n",
    "    \"ìˆ˜í•™ (EN)\": [\"-\", \"-\", \"65%\", \"65%\"],\n",
    "    \"ì–¸ì–´ ì •ë ¬\": [\"-\", \"-\", \"-\", \"PT-PT\"],\n",
    "    \"í•™ìŠµ ì‹œê°„\": [\"0ë¶„\", \"2-3ë¶„\", \"2-3ë¶„\", \"5ë¶„\"],\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ì¢…í•© ì„±ëŠ¥ ë¹„êµ\")\n",
    "print(\"=\"*80)\n",
    "display(performance_summary)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ì§€ì‹ ìŠµë“\n",
    "models = [\"Base\", \"CPT\"]\n",
    "knowledge = [55, 59]\n",
    "axes[0].bar(models, knowledge, color=['#1f77b4', '#76b900'])\n",
    "axes[0].set_ylabel('ì •í™•ë„ (%)', fontsize=12)\n",
    "axes[0].set_title('ì§€ì‹ ìŠµë“ (GTC 2025)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylim(0, 100)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# ì‘ì—… ëŠ¥ë ¥\n",
    "models = [\"Base\", \"SFT\"]\n",
    "math_es = [16, 52]\n",
    "math_en = [20, 65]\n",
    "x = range(len(models))\n",
    "width = 0.35\n",
    "axes[1].bar([i - width/2 for i in x], math_es, width, label='ìŠ¤í˜ì¸ì–´', color='#ff7f0e')\n",
    "axes[1].bar([i + width/2 for i in x], math_en, width, label='ì˜ì–´', color='#2ca02c')\n",
    "axes[1].set_ylabel('ì •í™•ë„ (%)', fontsize=12)\n",
    "axes[1].set_title('ìˆ˜í•™ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(models)\n",
    "axes[1].set_ylim(0, 100)\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 ì‚¬ìš© ì‚¬ë¡€ë³„ ê¶Œì¥ì‚¬í•­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = {\n",
    "    \"CPT ì‚¬ìš© ê¶Œì¥\": [\n",
    "        \"âœ… ì •ì ì¸ ëŒ€ê·œëª¨ ë„ë©”ì¸ ë°ì´í„° ì¡´ì¬\",\n",
    "        \"âœ… ì´ˆì €ì§€ì—° í•„ìš”\",\n",
    "        \"âœ… ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì¶•ì†Œ í•„ìš”\",\n",
    "        \"âœ… ê³ ë„ì˜ ì „ë¬¸ì„± í•„ìš”\",\n",
    "        \"âŒ ëŒ€ë¶€ë¶„ì˜ ê²½ìš° RAGê°€ ë” ì í•©\",\n",
    "    ],\n",
    "    \"SFT ì‚¬ìš© ê¶Œì¥\": [\n",
    "        \"âœ… íŠ¹ì • ì‘ì—… ëŠ¥ë ¥ í–¥ìƒ í•„ìš”\",\n",
    "        \"âœ… ì–¸ì–´ ì ì‘ í•„ìš”\",\n",
    "        \"âœ… ì¶”ë¡  íŒ¨í„´ ë„ì…\",\n",
    "        \"âœ… ë¬¸ì²´ ì œì–´ í•„ìš”\",\n",
    "        \"âœ… ê°€ì¥ ë²”ìš©ì ìœ¼ë¡œ ìœ ìš©\",\n",
    "    ],\n",
    "    \"DPO ì‚¬ìš© ê¶Œì¥\": [\n",
    "        \"âœ… ìŠ¤íƒ€ì¼/ì–´ì¡° ì •ë ¬\",\n",
    "        \"âœ… ì•ˆì „ì„± í–¥ìƒ\",\n",
    "        \"âœ… ì„ í˜¸ë„ í•™ìŠµ\",\n",
    "        \"âœ… RLHF ëŒ€ì•ˆìœ¼ë¡œ ê°„ë‹¨\",\n",
    "        \"âœ… ë§ˆì§€ë§‰ ë‹¨ê³„ë¡œ ì ìš©\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ì‚¬ìš© ì‚¬ë¡€ë³„ ê¶Œì¥ì‚¬í•­\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for category, items in recommendations.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for item in items:\n",
    "        print(f\"  {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 ì „ì²´ íŒŒì´í”„ë¼ì¸ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "==================================================================================\n",
    "NVIDIA NeMo íŒŒì¸íŠœë‹ íŒŒì´í”„ë¼ì¸ ìš”ì•½\n",
    "==================================================================================\n",
    "\n",
    "1. ì§€ì†ì  ì‚¬ì „ í•™ìŠµ (CPT)\n",
    "   ëª©ì : ë„ë©”ì¸ ì§€ì‹ ì£¼ì…\n",
    "   ë°ì´í„°: ëŒ€ëŸ‰ì˜ ì›ì‹œ í…ìŠ¤íŠ¸\n",
    "   ê²°ê³¼: GTC 2025 ì§€ì‹ ìŠµë“ (55% â†’ 59%)\n",
    "   ì£¼ì˜: íŒŒêµ­ì  ë§ê° ìœ„í—˜, ëŒ€ë¶€ë¶„ì˜ ê²½ìš° RAG ê¶Œì¥\n",
    "\n",
    "2. ì§€ë„ ë¯¸ì„¸ ì¡°ì • (SFT)\n",
    "   ëª©ì : ì‘ì—… ëŠ¥ë ¥ í–¥ìƒ\n",
    "   ë°ì´í„°: ì…ë ¥-ì¶œë ¥ ìŒ\n",
    "   ê²°ê³¼: ìŠ¤í˜ì¸ì–´ ìˆ˜í•™ 52% (16% ëŒ€ë¹„ +36%p)\n",
    "   íŠ¹ì§•: êµì°¨ ì–¸ì–´ ì „ì´ ë°œìƒ\n",
    "\n",
    "3. ì§ì ‘ ì„ í˜¸ë„ ìµœì í™” (DPO)\n",
    "   ëª©ì : ì¸ê°„ ì„ í˜¸ë„ ì •ë ¬\n",
    "   ë°ì´í„°: ì„ í˜¸/ë¹„ì„ í˜¸ ìŒ\n",
    "   ê²°ê³¼: PT-PT ì–¸ì–´ ë³€í˜• ì„ í˜¸ë„ í•™ìŠµ\n",
    "   ì¥ì : RLHFë³´ë‹¤ ê°„ë‹¨í•˜ê³  íš¨ìœ¨ì \n",
    "\n",
    "==================================================================================\n",
    "ê¶Œì¥ ì›Œí¬í”Œë¡œìš°\n",
    "==================================================================================\n",
    "\n",
    "ì¼ë°˜ì ì¸ ê²½ìš°:\n",
    "  Base Model â†’ SFT â†’ DPO â†’ Production\n",
    "\n",
    "ë„ë©”ì¸ ì „ë¬¸ì„± í•„ìš” ì‹œ:\n",
    "  Base Model â†’ CPT â†’ SFT â†’ DPO â†’ Production\n",
    "\n",
    "ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘:\n",
    "  Base Model â†’ RAG (CPT ëŒ€ì‹ )\n",
    "\n",
    "==================================================================================\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë§ˆë¬´ë¦¬\n",
    "\n",
    "### í•™ìŠµ ë‚´ìš© ì •ë¦¬\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì„ í†µí•´ ë‹¤ìŒì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. **NeMo Run í”„ë ˆì„ì›Œí¬**\n",
    "   - ë ˆì‹œí”¼ ê¸°ë°˜ ì‹¤í—˜ êµ¬ì„±\n",
    "   - ë¶„ì‚° í•™ìŠµ ê´€ë¦¬\n",
    "   - ì²´í¬í¬ì¸íŠ¸ ë° ë¡œê¹…\n",
    "\n",
    "2. **ì§€ì†ì  ì‚¬ì „ í•™ìŠµ (CPT)**\n",
    "   - ë„ë©”ì¸ ì§€ì‹ ì£¼ì…\n",
    "   - ë°ì´í„° í† í°í™”\n",
    "   - CPT vs. RAG ë¹„êµ\n",
    "\n",
    "3. **ì§€ë„ ë¯¸ì„¸ ì¡°ì • (SFT)**\n",
    "   - ì‘ì—… ëŠ¥ë ¥ í–¥ìƒ\n",
    "   - ì–¸ì–´ ì ì‘\n",
    "   - êµì°¨ ì–¸ì–´ ì „ì´\n",
    "\n",
    "4. **ì§ì ‘ ì„ í˜¸ë„ ìµœì í™” (DPO)**\n",
    "   - ì„ í˜¸ë„ ì •ë ¬\n",
    "   - NeMo-RL ì‚¬ìš©\n",
    "   - RLHF ëŒ€ì•ˆ\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "- ê°œë³„ ë…¸íŠ¸ë¶ìœ¼ë¡œ ê° ê¸°ë²• ì‹¬í™” í•™ìŠµ\n",
    "- ìì‹ ì˜ ë°ì´í„°ë¡œ ì‹¤í—˜\n",
    "- í”„ë¡œë•ì…˜ ë°°í¬ ê³ ë ¤\n",
    "- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
